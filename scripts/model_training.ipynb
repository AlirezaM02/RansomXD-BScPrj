{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a38ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_training.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from .preprocess_features import train_test_split\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e172ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data(data_path):\n",
    "    \"\"\"Load preprocessed data from pickle file\"\"\"\n",
    "    with open(data_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return (\n",
    "        data[\"X_train\"],\n",
    "        data[\"X_test\"],\n",
    "        data[\"y_train\"],\n",
    "        data[\"y_test\"],\n",
    "        data[\"feature_names\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa22b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(X_train, y_train):\n",
    "    \"\"\"Train and return Random Forest model\"\"\"\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        class_weight=\"balanced\",\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ccacff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(X_train, y_train):\n",
    "    \"\"\"Train and return XGBoost model\"\"\"\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.1,\n",
    "        scale_pos_weight=np.sum(y_train == 0) / np.sum(y_train == 1),\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"logloss\",\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9beee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Architecture\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129189ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Train PyTorch MLP model\"\"\"\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.FloatTensor(y_train).unsqueeze(1)\n",
    "    X_val_tensor = torch.FloatTensor(X_val)\n",
    "    y_val_tensor = torch.FloatTensor(y_val).unsqueeze(1)\n",
    "\n",
    "    # Create datasets and loaders\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # Initialize model, loss, and optimizer\n",
    "    model = MLP(X_train.shape[1])\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    best_val_recall = 0\n",
    "    patience_counter = 0\n",
    "    patience = 5\n",
    "\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val_tensor)\n",
    "            val_preds = (val_outputs > 0.5).float()\n",
    "            val_recall = recall_score(y_val, val_preds.numpy())\n",
    "\n",
    "            # Early stopping\n",
    "            if val_recall > best_val_recall:\n",
    "                best_val_recall = val_recall\n",
    "                patience_counter = 0\n",
    "                best_weights = model.state_dict()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "    # Load best weights\n",
    "    model.load_state_dict(best_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac77440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"Evaluate model and return metrics\"\"\"\n",
    "    if isinstance(model, MLP):  # PyTorch model\n",
    "        with torch.no_grad():\n",
    "            X_test_tensor = torch.FloatTensor(X_test)\n",
    "            y_pred_proba = model(X_test_tensor).numpy()\n",
    "            y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    else:  # Traditional models\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred),\n",
    "        \"recall\": recall_score(y_test, y_pred),\n",
    "        \"f1\": f1_score(y_test, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y_test, y_pred),\n",
    "        \"confusion_matrix\": confusion_matrix(y_test, y_pred).tolist(),\n",
    "        \"classification_report\": classification_report(\n",
    "            y_test, y_pred, output_dict=True\n",
    "        ),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1086eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name):\n",
    "    \"\"\"Save trained model to disk\"\"\"\n",
    "    models_dir = \"models\"\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "    if isinstance(model, MLP):\n",
    "        torch.save(model.state_dict(), os.path.join(models_dir, f\"{model_name}.pth\"))\n",
    "    else:\n",
    "        with open(os.path.join(models_dir, f\"{model_name}.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b617fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curves(models, X_test, y_test):\n",
    "    \"\"\"Plot ROC curves for each model\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for name, model in models.items():\n",
    "        if isinstance(model, MLP):\n",
    "            with torch.no_grad():\n",
    "                X_test_tensor = torch.FloatTensor(X_test)\n",
    "                y_pred_proba = model(X_test_tensor).numpy()\n",
    "        else:\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC = {auc:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e3981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load preprocessed data\n",
    "    X_train, X_test, y_train, y_test, feature_names = load_preprocessed_data(\n",
    "        \"data/processed/dataset.pkl\"\n",
    "    )\n",
    "\n",
    "    # Split validation set from training data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    "    )\n",
    "\n",
    "    # Train models\n",
    "    models = {\n",
    "        \"RandomForest\": train_random_forest(X_train, y_train),\n",
    "        \"XGBoost\": train_xgboost(X_train, y_train),\n",
    "    }\n",
    "\n",
    "    # Train MLP\n",
    "    mlp_model, mlp_history = train_mlp(X_train, y_train, X_val, y_val)\n",
    "    models[\"MLP\"] = mlp_model\n",
    "\n",
    "    # Evaluate models\n",
    "    metrics = []\n",
    "    for name, model in models.items():\n",
    "        model_metrics = evaluate_model(model, X_test, y_test, name)\n",
    "        metrics.append(model_metrics)\n",
    "        save_model(model, name)\n",
    "\n",
    "        # Save and visualize results\n",
    "        save_results(metrics)\n",
    "        plot_roc_curves(models, X_test, y_test)\n",
    "\n",
    "        # Print summary\n",
    "        print(\"\\n=== Model Performance Summary ===\")\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], \"k--\", label=\"Baseline\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC Curves\")\n",
    "        plt.legend()\n",
    "        plt.savefig(\"reports/roc_curves.png\")\n",
    "        plt.show()\n",
    "    print(\n",
    "        pd.DataFrame(metrics).drop(\n",
    "            [\"confusion_matrix\", \"classification_report\"], axis=1\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fa423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
