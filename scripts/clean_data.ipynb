{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d64c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_cleaning.py\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c09cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_single_file(df, is_benign=True):\n",
    "    \"\"\"Cleans an individual file (benign or ransomware)\"\"\"\n",
    "    # Convert Persian numbers in critical columns\n",
    "    # Persian digit conversion mapping\n",
    "    persian_map = {\n",
    "        \"۰\": \"0\",\n",
    "        \"۱\": \"1\",\n",
    "        \"۲\": \"2\",\n",
    "        \"۳\": \"3\",\n",
    "        \"۴\": \"4\",\n",
    "        \"۵\": \"5\",\n",
    "        \"۶\": \"6\",\n",
    "        \"۷\": \"7\",\n",
    "        \"۸\": \"8\",\n",
    "        \"۹\": \"9\",\n",
    "    }\n",
    "    numeric_cols = [\"ID\", \"CUCKOO_ID\", \"MALICIOUS\", \"DOWNLOADED\"]\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = (\n",
    "                df[col].astype(str).str.strip('\"').replace(persian_map, regex=True)\n",
    "            )\n",
    "\n",
    "            df[col] = pd.to_numeric(df[col].replace(\"\", \"0\"), errors=\"coerce\")\n",
    "\n",
    "    # Clean text columns\n",
    "    text_cols = [\"NAME\", \"LOCATION\", \"CATEGORY\"]\n",
    "    for col in text_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = (\n",
    "                df[col]\n",
    "                .astype(str)\n",
    "                .str.strip('\"')\n",
    "                .str.split(\"\\\\\")\n",
    "                .str[-1]  # Windows path\n",
    "                .str.split(\"/\")\n",
    "                .str[-1]\n",
    "            )  # Unix path\n",
    "\n",
    "    # Set MALICIOUS flag\n",
    "    df[\"MALICIOUS\"] = 0 if is_benign else 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9031b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_files(benign_path, ransom_path):\n",
    "    \"\"\"\n",
    "    Loads, cleans, and combines the benign and ransomware datasets.\n",
    "    Returns a single cleaned and shuffled DataFrame.\n",
    "    \"\"\"\n",
    "    # Load and clean both datasets\n",
    "    benign_df = clean_single_file(pd.read_csv(benign_path), is_benign=True)\n",
    "    ransom_df = clean_single_file(pd.read_csv(ransom_path), is_benign=False)\n",
    "\n",
    "    # Combine and shuffle\n",
    "    combined_df = pd.concat([benign_df, ransom_df], ignore_index=True)\n",
    "    return combined_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8393fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cleaned_data(combined_df, output_dir):\n",
    "    \"\"\"\n",
    "    Saves the cleaned and combined data to both CSV and pickle formats.\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save to CSV\n",
    "    csv_path = output_dir / \"cleaned_combined_data.csv\"\n",
    "    combined_df.to_csv(csv_path, index=False)\n",
    "\n",
    "    # Save to pickle\n",
    "    pickle_path = output_dir / \"cleaned_combined_data.pkl\"\n",
    "    with open(pickle_path, \"wb\") as f:\n",
    "        pickle.dump(combined_df, f)\n",
    "\n",
    "    print(f\"\\nCleaned data saved to:\")\n",
    "    print(f\"- CSV: {csv_path}\")\n",
    "    print(f\"- Pickle: {pickle_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745ff80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_demo(input_dir, output_dir):\n",
    "    \"\"\"Demonstrates the cleaning and combining process\"\"\"\n",
    "    input_path = Path(input_dir)\n",
    "\n",
    "    # Show before cleaning\n",
    "    raw_benign = pd.read_csv(input_path / \"benign.csv\").head(3)\n",
    "    raw_ransom = pd.read_csv(input_path / \"ransom.csv\").head(3)\n",
    "\n",
    "    print(\"\\n=== Raw Data Demonstration ===\")\n",
    "    print(\"\\nSample Before Cleaning (Benign):\")\n",
    "    print(raw_benign[[\"ID\", \"NAME\", \"CUCKOO_ID\", \"MALICIOUS\"]])\n",
    "\n",
    "    print(\"\\nSample Before Cleaning (Ransom):\")\n",
    "    print(raw_ransom[[\"ID\", \"NAME\", \"CUCKOO_ID\", \"MALICIOUS\"]])\n",
    "\n",
    "    # Clean and combine data\n",
    "    combined_df = load_and_clean_files(\n",
    "        input_path / \"benign.csv\", input_path / \"ransom.csv\"\n",
    "    )\n",
    "\n",
    "    # Show after cleaning\n",
    "    print(\"\\nSample After Cleaning (Combined):\")\n",
    "    print(combined_df[[\"ID\", \"NAME\", \"CUCKOO_ID\", \"MALICIOUS\"]].head(5))\n",
    "\n",
    "    # Save cleaned data\n",
    "    save_cleaned_data(combined_df, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e9075",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Data cleaning demonstration\")\n",
    "    parser.add_argument(\n",
    "        \"--input\",\n",
    "        type=str,\n",
    "        default=\"data/raw\",\n",
    "        help=\"Input directory containing raw CSV files\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output\",\n",
    "        type=str,\n",
    "        default=\"data/cleaned\",\n",
    "        help=\"Output directory for cleaned CSV and pickle files\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    cleaning_demo(args.input, args.output)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
